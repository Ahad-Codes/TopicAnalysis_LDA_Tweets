{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_sentences = [\n",
    "    \"the COVID-19 vaccine rollout has been effective in reducing the number of cases.\",\n",
    "    \"New variants of the coronavirus are causing a lot of concern among health experts.\",\n",
    "    \"Many people are hesitant about the COVID vaccine due to misinformation.\",\n",
    "    \"Hospitals are overwhelmed due to the surge in COVID-19 cases.\",\n",
    "    \"The pandemic has led to a significant increase in mental health issues worldwide.\",\n",
    "    \"Researchers are studying the long-term effects of COVID-19 on the human body.\",\n",
    "    \"Remote work has become the new norm since the COVID pandemic started.\",\n",
    "    \"Many countries are implementing stricter lockdowns to control the spread of COVID-19.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 52, 'covid': 12, 'vaccine': 54, 'rollout': 44, 'has': 17, 'been': 4, 'effective': 14, 'in': 23, 'reducing': 41, 'number': 35, 'of': 36, 'cases': 6, 'new': 33, 'variants': 55, 'coronavirus': 10, 'are': 2, 'causing': 7, 'lot': 29, 'concern': 8, 'among': 1, 'health': 18, 'experts': 16, 'many': 30, 'people': 40, 'hesitant': 19, 'about': 0, 'due': 13, 'to': 53, 'misinformation': 32, 'hospitals': 20, 'overwhelmed': 38, 'surge': 51, 'pandemic': 39, 'led': 26, 'significant': 45, 'increase': 24, 'mental': 31, 'issues': 25, 'worldwide': 57, 'researchers': 43, 'studying': 50, 'longterm': 28, 'effects': 15, 'on': 37, 'human': 21, 'body': 5, 'remote': 42, 'work': 56, 'become': 3, 'norm': 34, 'since': 46, 'started': 48, 'countries': 11, 'implementing': 22, 'stricter': 49, 'lockdowns': 27, 'control': 9, 'spread': 47}\n",
      "{52: 'the', 12: 'covid', 54: 'vaccine', 44: 'rollout', 17: 'has', 4: 'been', 14: 'effective', 23: 'in', 41: 'reducing', 35: 'number', 36: 'of', 6: 'cases', 33: 'new', 55: 'variants', 10: 'coronavirus', 2: 'are', 7: 'causing', 29: 'lot', 8: 'concern', 1: 'among', 18: 'health', 16: 'experts', 30: 'many', 40: 'people', 19: 'hesitant', 0: 'about', 13: 'due', 53: 'to', 32: 'misinformation', 20: 'hospitals', 38: 'overwhelmed', 51: 'surge', 39: 'pandemic', 26: 'led', 45: 'significant', 24: 'increase', 31: 'mental', 25: 'issues', 57: 'worldwide', 43: 'researchers', 50: 'studying', 28: 'longterm', 15: 'effects', 37: 'on', 21: 'human', 5: 'body', 42: 'remote', 56: 'work', 3: 'become', 34: 'norm', 46: 'since', 48: 'started', 11: 'countries', 22: 'implementing', 49: 'stricter', 27: 'lockdowns', 9: 'control', 47: 'spread'}\n",
      "'a'\n",
      "'a'\n",
      "Assigned Topics : [[2, 2, 1, 2, 0, 1, 0, 0, 2, 1, 1, 1, 1], [0, 0, 2, 1, 1, 1, 0, 2, 2, 1, 1, 0, 1], [0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0], [1, 1, 2, 1, 1, 0, 0, 2, 0, 2], [2, 0, 0, 1, 2, 0, 1, 2, 1, 1, 2, 2], [0, 0, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1], [0, 1, 1, 2, 1, 2, 1, 1, 2, 0, 1, 2], [2, 0, 2, 2, 0, 1, 0, 2, 1, 0, 0, 2]]\n"
     ]
    }
   ],
   "source": [
    "class LDA():\n",
    "\n",
    "    def __init__(self, docs, k, iterations, alpha, beta):\n",
    "        self.k = k\n",
    "        self.iterations = iterations\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.docs = self.preprocess_texts(docs)\n",
    "\n",
    "        self.num_docs = len(docs)\n",
    "\n",
    "        # Setting vocab and id mappings\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizer.fit(self.docs)\n",
    "        self.vocab = vectorizer.get_feature_names_out()\n",
    "        self.word2id = vectorizer.vocabulary_\n",
    "        print(self.word2id)\n",
    "        self.id2word = {idx: word for word, idx in self.word2id.items()}\n",
    "        print(self.id2word)\n",
    "        \n",
    "        # Counts needed for gibbs sampling\n",
    "        self.doc_topic_count = np.zeros((self.num_docs, self.k))\n",
    "        self.topic_word_count = np.zeros((self.k, len(self.vocab)))\n",
    "        self.topic_total_counts = np.zeros(self.k)\n",
    "        self.doc_lengths = np.zeros(self.num_docs)\n",
    "        self.assigned_topics = []\n",
    "\n",
    "    def preprocess_texts(self,texts):\n",
    "        processed_texts = []\n",
    "        for text in texts:\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'[^\\w\\s_]', '', text)\n",
    "            text = re.sub(r'\\d+', '', text)\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            processed_texts.append(text)\n",
    "        return processed_texts\n",
    "\n",
    "    def init_assignment(self):\n",
    "\n",
    "        for t, tweet in enumerate(self.docs):\n",
    "            words = tweet.split()\n",
    "            curr_doc_topic = []\n",
    "\n",
    "            for w, word in enumerate(words):\n",
    "                try:\n",
    "                    word = word.lower()\n",
    "                    rand_topic = np.random.randint(self.k)\n",
    "                    word_id = self.word2id[word]\n",
    "                    curr_doc_topic.append(rand_topic)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "                \n",
    "                self.doc_topic_count[t, rand_topic] += 1\n",
    "                self.topic_word_count[rand_topic, word_id] += 1\n",
    "                self.topic_total_counts[rand_topic] += 1\n",
    "\n",
    "            self.assigned_topics.append(curr_doc_topic)\n",
    "            \n",
    "            \n",
    "\n",
    "    def pipeline(self):\n",
    "        self.init_assignment()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "lda_model = LDA(covid_sentences, 3, 1000, 0.1, 0.1)\n",
    "lda_model.pipeline()\n",
    "print(f\"Assigned Topics : {lda_model.assigned_topics}\")\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
